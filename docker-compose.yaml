name: fraudsys
services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.0.1
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000

  broker:
    image: confluentinc/cp-kafka:7.0.1
    container_name: broker
    ports:
      - "9092:9092"
      - "29092:29092"
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_INTERNAL:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092,PLAINTEXT_INTERNAL://broker:29092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1

  kafka-ui:
    container_name: kafka-ui
    image: provectuslabs/kafka-ui:latest
    ports:
      - "8080:8080"
    depends_on:
      - zookeeper
      - broker
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: broker:29092

  redis:
    image: redis
    container_name: redis
    ports:
      - "6379:6379"

  feature-api:
    container_name: feature-api
    restart: always
    build:
      context: .
      dockerfile: .docker/api.Dockerfile
    ports:
    - "8000:8000"
    depends_on:
      - broker
      - redis
    environment:
      - KAGGLE_KEY=${KAGGLE_KEY}
      - KAGGLE_USERNAME=${KAGGLE_USERNAME}
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}

  feature-producer:
    container_name: feature-producer
    restart: always
    build:
      context: .
      dockerfile: .docker/producer.Dockerfile
    depends_on:
      - broker
      - redis
      - feature-api
    environment:
      - KAGGLE_KEY=${KAGGLE_KEY}
      - KAGGLE_USERNAME=${KAGGLE_USERNAME}
    volumes:
      - ./data/prod:/app/data/prod:ro  # :ro for read-only


  feature-cleaner:
    container_name: feature-cleaner
    restart: always
    build:
      context: .
      dockerfile: .docker/feature.Dockerfile
    depends_on:
      - broker
      - redis
      - feature-producer
    environment:
      - KAGGLE_KEY=${KAGGLE_KEY}
      - KAGGLE_USERNAME=${KAGGLE_USERNAME}

  mlflow-db:
    image: postgres:14
    container_name: mlflow-db
    environment:
      POSTGRES_USER: mlflow
      POSTGRES_PASSWORD: mlflow_pass
      POSTGRES_DB: mlflow_db
    volumes:
      - ./postgres-data:/var/lib/postgresql/data
    ports:
      - "5432:5432"

  mlflow:
    container_name: mlflow
    build:
      context: .
      dockerfile: .docker/mlflow.Dockerfile
    ports:
      - "5001:5000"
    depends_on:
      - mlflow-db
    environment:
      - MLFLOW_TRACKING_URI=http://localhost:5001
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
    command: >
      mlflow server
      --host 0.0.0.0
      --port 5000
      --backend-store-uri postgresql+psycopg2://mlflow:mlflow_pass@mlflow-db:5432/mlflow_db
      --default-artifact-root s3://fraudsys-dev-mlflow-artifacts
      --serve-artifacts

  prediction-monitoring:
    container_name: prediction-monitoring
    restart: always
    build:
      context: .
      dockerfile: .docker/monitoring.Dockerfile
    ports:
      - "8001:8001"
    depends_on:
      - feature-api
    environment:
      - KAGGLE_KEY=${KAGGLE_KEY}
      - KAGGLE_USERNAME=${KAGGLE_USERNAME}

  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    volumes:
      - ./confs/services/prometheus.yaml:/etc/prometheus/prometheus.yml:ro
    ports:
      - "9090:9090"
    depends_on:
      - prediction-monitoring #Â needs predictions to made first

  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    ports:
      - "3000:3000"
    depends_on:
      - prometheus
